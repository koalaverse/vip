<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Compute model-specific variable importance scores for the predictors in a
fitted model."><title>Model-specific variable importance — vi_model • vip</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model-specific variable importance — vi_model"><meta property="og:description" content="Compute model-specific variable importance scores for the predictors in a
fitted model."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">vip</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../articles/vip.html">Get started</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/koalaverse/vip/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Model-specific variable importance</h1>
      <small class="dont-index">Source: <a href="https://github.com/koalaverse/vip/blob/HEAD/R/vi_model.R" class="external-link"><code>R/vi_model.R</code></a></small>
      <div class="d-none name"><code>vi_model.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Compute model-specific variable importance scores for the predictors in a
fitted model.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for default</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for C5.0</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"usage"</span>, <span class="st">"splits"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for train</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for cubist</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for earth</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"nsubsets"</span>, <span class="st">"rss"</span>, <span class="st">"gcv"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for gbm</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"relative.influence"</span>, <span class="st">"permutation"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for glmnet</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, lambda <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for cv.glmnet</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, lambda <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for H2OBinomialModel</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for H2OMultinomialModel</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for H2ORegressionModel</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mixo_pls</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, ncomp <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mixo_spls</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, ncomp <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for WrappedModel</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for Learner</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for nn</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"olden"</span>, <span class="st">"garson"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for nnet</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"olden"</span>, <span class="st">"garson"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for RandomForest</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"accuracy"</span>, <span class="st">"auc"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for constparty</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for cforest</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mvr</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mixo_pls</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, ncomp <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mixo_spls</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, ncomp <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for WrappedModel</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for Learner</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for randomForest</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ranger</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for rpart</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for mlp</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"olden"</span>, <span class="st">"garson"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_decision_tree_regression</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_decision_tree_classification</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_gbt_regression</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_gbt_classification</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_generalized_linear_regression</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_linear_regression</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_random_forest_regression</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for ml_model_random_forest_classification</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for lm</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"stat"</span>, <span class="st">"raw"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for model_fit</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for workflow</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for xgb.Booster</span></span>
<span><span class="fu">vi_model</span><span class="op">(</span><span class="va">object</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gain"</span>, <span class="st">"cover"</span>, <span class="st">"frequency"</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>object</dt>
<dd><p>A fitted model object (e.g., a <code>"randomForest"</code> object).</p></dd>


<dt>...</dt>
<dd><p>Additional optional arguments to be passed on to other methods.</p></dd>


<dt>type</dt>
<dd><p>Character string specifying the type of variable importance to
return (only used for some models). See details for which methods this
argument applies to.</p></dd>


<dt>lambda</dt>
<dd><p>Numeric value for the penalty parameter of a
<code><a href="https://glmnet.stanford.edu/reference/glmnet.html" class="external-link">glmnet</a></code> model (this is equivalent to the <code>s</code>
argument in <code><a href="https://glmnet.stanford.edu/reference/predict.glmnet.html" class="external-link">coef.glmnet</a></code>). See the section on
<code><a href="https://glmnet.stanford.edu/reference/glmnet.html" class="external-link">glmnet</a></code> in the details below.</p></dd>


<dt>ncomp</dt>
<dd><p>An integer for the number of partial least squares components
to be used in the importance calculations. If more components are requested
than were used in the model, all of the model's components are used.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>A tidy data frame (i.e., a <code>"tibble"</code> object) with two columns:
<code>Variable</code> and <code>Importance</code>. For <code>"lm"/"glm"</code>-like object, an
additional column, called <code>Sign</code>, is also included which includes the
sign (i.e., POS/NEG) of the original coefficient.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Computes model-specific variable importance scores depending on the class of
<code>object</code>:</p>
<dl><dt><code><a href="https://topepo.github.io/C5.0/reference/C5.0.html" class="external-link">C5.0</a></code></dt>
<dd><p>Variable importance is measured by determining
the percentage of training set samples that fall into all the terminal nodes
after the split. For example, the predictor in the first split automatically
has an importance measurement of 100 percent since all samples are affected
by this split. Other predictors may be used frequently in splits, but if the
terminal nodes cover only a handful of training set samples, the importance
scores may be close to zero. The same strategy is applied to rule-based
models and boosted versions of the model. The underlying function can also
return the number of times each predictor was involved in a split by using
the option <code>metric = "usage"</code>. See <code><a href="https://topepo.github.io/C5.0/reference/C5imp.html" class="external-link">C5imp</a></code> for
details.</p></dd>


<dt><code><a href="http://topepo.github.io/Cubist/reference/cubist.default.html" class="external-link">cubist</a></code></dt>
<dd><p>The Cubist output contains variable usage
statistics. It gives the percentage of times where each variable was used in
a condition and/or a linear model. Note that this output will probably be
inconsistent with the rules shown in the output from summary.cubist. At each
split of the tree, Cubist saves a linear model (after feature selection) that
is allowed to have terms for each variable used in the current split or any
split above it. Quinlan (1992) discusses a smoothing algorithm where each
model prediction is a linear combination of the parent and child model along
the tree. As such, the final prediction is a function of all the linear
models from the initial node to the terminal node. The percentages shown in
the Cubist output reflects all the models involved in prediction (as opposed
to the terminal models shown in the output). The variable importance used
here is a linear combination of the usage in the rule conditions and the
model. See <code><a href="http://topepo.github.io/Cubist/reference/summary.cubist.html" class="external-link">summary.cubist</a></code> and
<code><a href="https://rdrr.io/pkg/caret/man/varImp.html" class="external-link">varImp.cubist</a></code> for details.</p></dd>


<dt><code><a href="https://glmnet.stanford.edu/reference/glmnet.html" class="external-link">glmnet</a></code></dt>
<dd><p>Similar to (generalized) linear models,
the absolute value of the coefficients are returned for a specific model.
It is important that the features  (and hence, the estimated coefficients) be
standardized prior to fitting the model. You can specify which coefficients
to return by passing the specific value of the penalty parameter via the
<code>lambda</code> argument (this is equivalent to the <code>s</code> argument in
<code><a href="https://glmnet.stanford.edu/reference/predict.glmnet.html" class="external-link">coef.glmnet</a></code>). By default, <code>lambda = NULL</code> and the coefficients
corresponding to the final penalty value in the sequence are returned; in
other words, you should ALWAYS SPECIFY <code>lambda</code>! For <code>"cv.glmnet"</code>
objects, the largest value of lambda such that the error is within one standard
error of the minimum is used by default. For <code>"multnet"</code> objects, the
coefficients corresponding to the first class are used; that is, the first
component of <code><a href="https://glmnet.stanford.edu/reference/predict.glmnet.html" class="external-link">coef.glmnet</a></code>.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/partykit/man/cforest.html" class="external-link">cforest</a></code></dt>
<dd><p>Variable importance is measured in a
way similar to those computed by <code><a href="https://rdrr.io/pkg/randomForest/man/importance.html" class="external-link">importance</a></code>.
Besides the standard version, a conditional version is available that
adjusts for correlations between predictor variables. If
<code>conditional = TRUE</code>, the importance of each variable is computed by
permuting within a grid defined by the predictors that are associated (with
1 - <em>p</em>-value greater than threshold) to the variable of interest. The
resulting variable importance score is conditional in the sense of beta
coefficients in regression models, but represents the effect of a variable in
both main effects and interactions. See Strobl et al. (2008) for details.
Note, however, that all random forest results are subject to random
variation. Thus, before interpreting the importance ranking, check whether
the same ranking is achieved with a different random seed - or otherwise
increase the number of trees ntree in <code><a href="https://rdrr.io/pkg/partykit/man/ctree_control.html" class="external-link">ctree_control</a></code>.
Note that in the presence of missings in the predictor variables the
procedure described in Hapfelmeier et al. (2012) is performed. See
<code><a href="https://rdrr.io/pkg/partykit/man/varimp.html" class="external-link">varimp</a></code> for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/earth/man/earth.html" class="external-link">earth</a></code></dt>
<dd><p>The <code><a href="https://rdrr.io/pkg/earth/man/earth.html" class="external-link">earth</a></code> package uses
three criteria for estimating the variable importance in a MARS model (see
<code><a href="https://rdrr.io/pkg/earth/man/evimp.html" class="external-link">evimp</a></code> for details):</p><ul><li><p>The <code>nsubsets</code> criterion (<code>type = "nsubsets"</code>) counts the
number of model subsets that include each feature. Variables that are
included in more subsets are considered more important. This is the
criterion used by <code><a href="https://rdrr.io/pkg/earth/man/summary.earth.html" class="external-link">summary.earth</a></code> to print variable
importance. By "subsets" we mean the subsets of terms generated by
<code>earth()</code>'s backward pass. There is one subset for each model size
(from one to the size of the selected model) and the subset is the best set
of terms for that model size. (These subsets are specified in the
<code>$prune.terms</code> component of <code>earth()</code>'s return value.) Only
subsets that are smaller than or equal in size to the final model are used
for estimating variable importance. This is the default method used by
<strong>vip</strong>.</p></li>
<li><p>The <code>rss</code> criterion (<code>type = "rss"</code>) first calculates the
decrease in the RSS for each subset relative to the previous subset during
<code>earth()</code>’s backward pass. (For multiple response models, RSS's are
calculated over all responses.) Then for each variable it sums these
decreases over all subsets that include the variable. Finally, for ease of
interpretation the summed decreases are scaled so the largest summed
decrease is 100. Variables which cause larger net decreases in the RSS are
considered more important.</p></li>
<li><p>The <code>gcv</code> criterion (<code>type = "gcv"</code>) is similar to the
<code>rss</code> approach, but uses the GCV statistic instead of the RSS. Note
that adding a variable can sometimes increase the GCV. (Adding the variable
has a deleterious effect on the model, as measured in terms of its
estimated predictive power on unseen data.) If that happens often enough,
the variable can have a negative total importance, and thus appear less
important than unused variables.</p></li>
</ul></dd>


<dt><code><a href="https://rdrr.io/pkg/gbm/man/gbm.html" class="external-link">gbm</a></code></dt>
<dd><p>Variable importance is computed using one of
two approaches (See <code><a href="https://rdrr.io/pkg/gbm/man/summary.gbm.html" class="external-link">summary.gbm</a></code> for details):</p><ul><li><p>The standard approach (<code>type = "relative.influence"</code>) described
in Friedman (2001). When <code>distribution = "gaussian"</code> this returns the
reduction of squared error attributable to each variable. For other loss
functions this returns the reduction attributable to each variable in sum
of squared error in predicting the gradient on each iteration. It describes
the <em>relative influence</em> of each variable in reducing the loss
function. This is the default method used by <strong>vip</strong>.</p></li>
<li><p>An experimental permutation-based approach
(<code>type = "permutation"</code>). This method randomly permutes each predictor
variable at a time and computes the associated reduction in predictive
performance. This is similar to the variable importance measures Leo
Breiman uses for random forests, but <strong>gbm</strong> currently computes using
the entire training dataset (not the out-of-bag observations).</p></li>
</ul></dd>


<dt><code><a href="https://rdrr.io/pkg/h2o/man/H2OModel-class.html" class="external-link">H2OModel</a></code></dt>
<dd><p>See <code><a href="https://rdrr.io/pkg/h2o/man/h2o.varimp.html" class="external-link">h2o.varimp</a></code> or visit
<a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/variable-importance.html" class="external-link">https://docs.h2o.ai/h2o/latest-stable/h2o-docs/variable-importance.html</a>
for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/nnet/man/nnet.html" class="external-link">nnet</a></code></dt>
<dd><p>Two popular methods for constructing variable
importance scores with neural networks are the Garson algorithm
(Garson 1991), later modified by Goh (1995), and the Olden algorithm
(Olden et al. 2004). For both algorithms, the basis of these importance
scores is the network’s connection weights. The Garson algorithm determines
variable importance by identifying all weighted connections between the nodes
of interest. Olden’s algorithm, on the other hand, uses the product of the
raw connection weights between each input and output neuron and sums the
product across all hidden neurons. This has been shown to outperform the
Garson method in various simulations. For DNNs, a similar method due to
Gedeon (1997) considers the weights connecting the input features to the
first two hidden layers (for simplicity and speed); but this method can be
slow for large networks.. To implement the Olden and Garson algorithms, use
<code>type = "olden"</code> and <code>type = "garson"</code>, respectively. See
<code><a href="https://rdrr.io/pkg/NeuralNetTools/man/garson.html" class="external-link">garson</a></code> and <code><a href="https://rdrr.io/pkg/NeuralNetTools/man/olden.html" class="external-link">olden</a></code>
for details.</p></dd>


<dt><code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></code></dt>
<dd><p>In (generalized) linear models, variable
importance is typically based on the absolute value of the corresponding
<em>t</em>-statistics. For such models, the sign of the original coefficient
is also returned. By default, <code>type = "stat"</code> is used; however, if the
inputs have been appropriately standardized then the raw coefficients can be
used with <code>type = "raw"</code>.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/sparklyr/man/ml_feature_importances.html" class="external-link">ml_feature_importances</a></code></dt>
<dd><p>The Spark ML
library provides standard variable importance for tree-based methods (e.g.,
random forests). See <code><a href="https://rdrr.io/pkg/sparklyr/man/ml_feature_importances.html" class="external-link">ml_feature_importances</a></code> for
details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html" class="external-link">randomForest</a></code></dt>
<dd><p>Random forests typically
provide two measures of variable importance. The first measure is computed
from permuting out-of-bag (OOB) data: for each tree, the prediction error on
the OOB portion of the data is recorded (error rate for classification and
MSE for regression). Then the same is done after permuting each predictor
variable. The difference between the two are then averaged over all trees in
the forest, and normalized by the standard deviation of the differences. If
the standard deviation of the differences is equal to 0 for a variable,
the division is not done (but the average is almost always equal to 0 in that
case). See <code><a href="https://rdrr.io/pkg/randomForest/man/importance.html" class="external-link">importance</a></code> for details, including
additional arguments that can be passed via the <code>...</code> argument.</p>
<p>The second measure is the total decrease in node impurities from splitting on
the variable, averaged over all trees. For classification, the node impurity
is measured by the Gini index. For regression, it is measured by residual sum
of squares. See <code><a href="https://rdrr.io/pkg/randomForest/man/importance.html" class="external-link">importance</a></code> for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/party/man/cforest.html" class="external-link">cforest</a></code></dt>
<dd><p>Same approach described in
<code><a href="https://rdrr.io/pkg/partykit/man/cforest.html" class="external-link">cforest</a></code> above. See <code><a href="https://rdrr.io/pkg/party/man/varimp.html" class="external-link">varimp</a></code> and
<code><a href="https://rdrr.io/pkg/party/man/varimp.html" class="external-link">varimpAUC</a></code> (if <code>type = "auc"</code>) for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/ranger/man/ranger.html" class="external-link">ranger</a></code></dt>
<dd><p>Variable importance for
<code><a href="https://rdrr.io/pkg/ranger/man/ranger.html" class="external-link">ranger</a></code> objects is computed in the usual way for random
forests. The approach used depends on the <code>importance</code> argument provided
in the initial call to <code><a href="https://rdrr.io/pkg/ranger/man/ranger.html" class="external-link">ranger</a></code>. See
<code><a href="https://rdrr.io/pkg/ranger/man/importance.ranger.html" class="external-link">importance</a></code> for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/rpart/man/rpart.html" class="external-link">rpart</a></code></dt>
<dd><p>As stated in one of the <strong>rpart</strong>
vignettes. A variable may appear in the tree many times, either as a primary
or a surrogate variable. An overall measure of variable importance is the sum
of the goodness of split measures for each split for which it was the primary
variable, plus "goodness" * (adjusted agreement) for all splits in which it
was a surrogate. Imagine two variables which were essentially duplicates of
each other; if we did not count surrogates, they would split the importance
with neither showing up as strongly as it should. See
<code><a href="https://rdrr.io/pkg/rpart/man/rpart.html" class="external-link">rpart</a></code> for details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/caret/man/train.html" class="external-link">train</a></code></dt>
<dd><p>Various model-specific and model-agnostic
approaches that depend on the learning algorithm employed in the original
call to <code><a href="https://rdrr.io/pkg/caret/man/train.html" class="external-link">train</a></code>. See <code><a href="https://rdrr.io/pkg/caret/man/varImp.html" class="external-link">varImp</a></code> for
details.</p></dd>


<dt><code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></code></dt>
<dd><p>For linear models, the variable
importance is the absolute magnitude of the estimated coefficients. For that
reason, in order to obtain a meaningful ranking by importance for a linear
model, the features need to be on the same scale (which you also would want
to do when using either L1 or L2 regularization). Otherwise, the approach
described in Friedman (2001) for <code><a href="https://rdrr.io/pkg/gbm/man/gbm.html" class="external-link">gbm</a></code>s is used. See
<code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgb.importance</a></code> for details. For tree models, you can
obtain three different types of variable importance:</p><ul><li><p>Using <code>type = "gain"</code> (the default) gives the fractional
contribution of each feature to the model based on the total gain of the
corresponding feature's splits.</p></li>
<li><p>Using <code>type = "cover"</code> gives the number of observations related
to each feature.</p></li>
<li><p>Using <code>type = "frequency"</code> gives the percentages representing
the relative number of times each feature has been used throughout each
tree in the ensemble.</p></li>
</ul></dd>



</dl></div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>Inspired by the <code><a href="https://rdrr.io/pkg/caret/man/varImp.html" class="external-link">varImp</a></code> function.</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Brandon M. Greenwell, Brad Boehmke, Bernie Gray.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

